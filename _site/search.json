[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Lab Journal",
    "section": "",
    "text": "#This is a template example for lab journaling. Students in the data science courses at the Institute of #Entrepreneurship will use this template to learn R for business analytics. Students can replace this text as they wish.\n\n# How to use\n\n#1. Accept the assignment and get your own github repo.\n\n#2. Blog/journal what you are doing in R, by editing the `.qmd` files. \n\n#3. See the links page for lots of helpful links on learning R.\n\n#4. Change everything to make it your own.\n\n#5. Make sure to render you website every time before you want to upload changes."
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "My Lab Journal",
    "section": "How to use",
    "text": "How to use\n\nAccept the assignment and get your own github repo.\nBlog/journal what you are doing in R, by editing the .qmd files.\nSee the links page for lots of helpful links on learning R.\nChange everything to make it your own.\nMake sure to render you website every time before you want to upload changes."
  },
  {
    "objectID": "content/01_journal/02_statistics.html",
    "href": "content/01_journal/02_statistics.html",
    "title": "Statistical Concepts",
    "section": "",
    "text": "1 Load data\n\nsetwd(\"D:/CausalDataScience/cdsba-LukasB2324/content/01_journal\")\nrandom_vars&lt;-readRDS(\"Data/random_vars.rds\")\n\n\n\n2 View data\n\nView(random_vars)\nglimpse_random_vars&lt;-glimpse(random_vars)\n\n#&gt; Rows: 1,000\n#&gt; Columns: 2\n#&gt; $ age    &lt;dbl&gt; 21, 34, 10, 68, 15, 50, 32, 14, 17, 26, 8, 28, 12, 34, 28, 59, …\n#&gt; $ income &lt;dbl&gt; 940, 6678, 22, 2392, 74, 5012, 6636, 36, 1365, 3763, 59, 3600, …\n\nglimpse_random_vars\n\n\n\n  \n\n\n\n\n\n3 Assignment 1\n\nage_data&lt;-random_vars[,1,drop=TRUE]\nincome_data&lt;-random_vars[,2,drop=TRUE]\n\nage_expect&lt;-mean(age_data)\nincome_expect&lt;-mean(income_data)\n\nage_standardDev&lt;-sd(age_data)\nincome_standardDev&lt;-sd(income_data)\n\nage_variance&lt;-age_standardDev^2\nincome_variance&lt;-income_standardDev^2\n\nsprintf(\"Expected value of 'age': %.2f; expected value of 'income': %.2f; standard deviation of 'age': %.2f; standard deviation of 'income': %.2f; variance of 'age': %.2f; variance of 'income': %.2f\", age_expect, income_expect, age_standardDev, income_standardDev, age_variance, income_variance)\n\n#&gt; [1] \"Expected value of 'age': 33.47; expected value of 'income': 3510.73; standard deviation of 'age': 18.46; standard deviation of 'income': 2936.94; variance of 'age': 340.61; variance of 'income': 8625645.84\"\n\n\n\n\n4 Assignment 2\nIt does not make sense to compare the standard deviations of the two variables age and income, because their units do not match. The standard deviation has the unit of the corresponding data. So the unit of age_standardDev is years and the unit of income_standardDev is a currency like Euro or Pound.\n\n\n5 Assignment 3\n\ncovariance&lt;-cov(age_data,income_data)\ncorrelation&lt;-cor(age_data,income_data)\nsprintf(\"Covariance between 'age' and 'income': %.2f; correlation between 'age' and 'income': %.2f\", covariance, correlation)\n\n#&gt; [1] \"Covariance between 'age' and 'income': 29700.15; correlation between 'age' and 'income': 0.55\"\n\n\n\n\n6 Assignment 4\nThe correlation is easier to interpret, because it is dimensionless and bound between -1 and 1. The correlation of about 0.55 indicates that the variables of age and income have a certain linear relationship, but it is rather moderate than very strong.\n\n\n7 Assignment 5\n\nincome_upto18 &lt;- random_vars %&gt;% filter(age %in% 0:18)\nincome_upto18 &lt;- income_upto18[,2]\nexpected_income_upto18&lt;-mean(income_upto18[,,drop=TRUE])\n\nincome_from18under65 &lt;- random_vars %&gt;% filter(age %in% 18:64)\nincome_from18under65 &lt;- income_from18under65[,2]\nexpect_income_from18under65&lt;-mean(income_from18under65[,,drop=TRUE])\n\nincome_from65up &lt;- random_vars %&gt;% filter(age %in% 65:150)\nincome_from65up &lt;- income_from65up[,2]\nexpected_income_from65up&lt;-mean(income_from65up[,,drop=TRUE])\n\nsprintf(\"E[income|age &lt;= 18] = %.2f; E[income|age element of [18,65)] = %.2f; E[income|age &gt;= 65] = %.2f\", expected_income_upto18, expect_income_from18under65, expected_income_from65up)\n\n#&gt; [1] \"E[income|age &lt;= 18] = 389.61; E[income|age element of [18,65)] = 4685.73; E[income|age &gt;= 65] = 1777.24\""
  },
  {
    "objectID": "content/01_journal/04_causality.html",
    "href": "content/01_journal/04_causality.html",
    "title": "Causality",
    "section": "",
    "text": "1 The original plot of the spurious correlation\n\n\n\n\n\n\n\n2 The replication\n\nlibrary(tidyverse)\n\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.4     ✔ readr     2.1.4\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.1\n#&gt; ✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n#&gt; ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n#&gt; ✔ purrr     1.0.2     \n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ndata_birthrates&lt;-data.frame(births=c(160,158,155,150,140,130,127,113,103,102,96)*1000,stork_pairs=c(67,68,47,52,42,34,32,26,22,19,15),year=c(1966,1965,1967,1968,1969,1970,1971,1972,1973,1974,1975))\n\nggplot(data=data_birthrates,mapping = aes(x=data_birthrates[,1],y=data_birthrates[,2],label=data_birthrates[,3])) +\n  geom_smooth(method='lm', formula= y ~ x, se = F) +\n  geom_point(size=3) +\n  geom_text(hjust=1.2,vjust=0) +\n  scale_color_brewer(type = \"qual\", palette = \"Dark2\") +\n  scale_x_reverse() +\n  labs(x = \"Number of live births in Baden-Württemberg\", y = \"Number of stork pairs in Baden-Württemberg\",\n      title = \"Correlation between the decrease in stork pairs and the decrease in births in Baden-Württemberg\") #labs(x = \"Zahl der Lebendgeborenen in Baden-Württemberg\", y = \"Zahl der Storchenpaare in Baden-Württemberg\", title = \"Korrelation zwischen dem Rückgang der Storchenpopulation und der Abnahme der Geburtenzahl in Baden-Württemberg\") \n\n#&gt; Warning: The following aesthetics were dropped during statistical transformation: label\n#&gt; ℹ This can happen when ggplot fails to infer the correct grouping structure in\n#&gt;   the data.\n#&gt; ℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n#&gt;   variable into a factor?"
  },
  {
    "objectID": "content/01_journal/09_iv.html",
    "href": "content/01_journal/09_iv.html",
    "title": "Instrumental Variables",
    "section": "",
    "text": "1 Load packages\n\nlibrary(tidyverse)\n\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.4     ✔ readr     2.1.4\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.1\n#&gt; ✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n#&gt; ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n#&gt; ✔ purrr     1.0.2     \n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(dagitty)\nlibrary(ggdag)\n\n#&gt; \n#&gt; Attache Paket: 'ggdag'\n#&gt; \n#&gt; Das folgende Objekt ist maskiert 'package:stats':\n#&gt; \n#&gt;     filter\n\nlibrary(MatchIt)\nlibrary(estimatr)\n\n\n\n2 Load data\n\nsetwd(\"D:/CausalDataScience/cdsba-LukasB2324/content/01_journal\")\nrand_enc_data&lt;-readRDS(\"Data/rand_enc.rds\")\n\n\n\n3 Assignment 1\n\nrand_enc_DAG &lt;- dagify(\n  Y ~ D,\n  Y ~ U,\n  D ~ U,\n  D ~ Z,\n  exposure = \"D\",\n  latent = \"U\",\n  outcome = \"Y\",\n  coords = list(x = c(U = 1, D = 0, Y = 2, Z = -1),\n                y = c(U = 1, D = 0, Y = 0, Z = 0)),\n  labels = c(\"D\" = \"Used new feature\", \n             \"Y\" = \"Time spent\", \n             \"U\" = \"Unknown confounders\",\n             \"Z\" = \"Popup\")\n)\nggdag(rand_enc_DAG, text = T) +\n  guides(color = \"none\") + \n  #geom_dag_point(color = ggthemr::swatch()[2]) +\n  geom_dag_text(color = \"white\") +\n  geom_dag_edges(edge_color = \"black\") +\n  geom_dag_label_repel(aes(label = label)) +\n  theme_dag_blank()\n\n\n\n\n\n\n\n\n\n\n4 Assignment 2\n\nlm_2&lt;-lm(time_spent~used_ftr,rand_enc_data)\nsummary(lm_2)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = time_spent ~ used_ftr, data = rand_enc_data)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -20.4950  -3.5393   0.0158   3.5961  20.5051 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) 18.86993    0.06955   271.3   &lt;2e-16 ***\n#&gt; used_ftr    10.82269    0.10888    99.4   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 5.351 on 9998 degrees of freedom\n#&gt; Multiple R-squared:  0.497,  Adjusted R-squared:  0.497 \n#&gt; F-statistic:  9881 on 1 and 9998 DF,  p-value: &lt; 2.2e-16\n\nsprintf(\"The naive estimate of the effect of the new feature is about %.2f.\",lm_2[[\"coefficients\"]][[\"used_ftr\"]])\n\n#&gt; [1] \"The naive estimate of the effect of the new feature is about 10.82.\"\n\n\n\n\n5 Assignment 3\n\ncor_matrix &lt;- cor(rand_enc_data) %&gt;% round(2)\ncor_matrix\n\n#&gt;            rand_enc used_ftr time_spent\n#&gt; rand_enc       1.00     0.20       0.13\n#&gt; used_ftr       0.20     1.00       0.71\n#&gt; time_spent     0.13     0.71       1.00\n\nplot_instrument_treat &lt;- ggplot(rand_enc_data[,c(1,2)], aes(x = rand_enc, y = used_ftr)) +\n  geom_point(alpha = .8) +\n  stat_smooth(method = \"lm\", se = F)\nplot_treat_outcome &lt;- ggplot(rand_enc_data[,c(2,3)], aes(x = used_ftr, y = time_spent)) +\n  geom_point(alpha = .8) +\n  stat_smooth(method = \"lm\", se = F)\nplot_instrument_outcome &lt;- ggplot(rand_enc_data[,c(1,3)], aes(x = rand_enc, y = time_spent)) +\n  geom_point(alpha = .8) +\n  stat_smooth(method = \"lm\", se = F)\nplot_instrument_treat\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nplot_treat_outcome\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nplot_instrument_outcome\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nsprintf(\"The plots show that the effect of the instrument on the treatment and on the outcome goes in the same direction (prerequisite 5 fullfilled). There is a correlation between the instrument 'rand_enc' and the treatment 'used_ftr', so the 4th prerequisite is fullfilled, altough the correlation is rather low (about %.2f). There is also a small correlation between the instrument 'rand_enc' and the outcome 'time_spent' of about %.2f. The correlation between the instrument and the treatment is only a little higher (%.2f) than the correlation between the treatment and the outcome, so the combination of treatment and instrument is not very suiting and the instrumental variable estimation is not a very adequate procedure in the given case.\", cor_matrix[1,2],cor_matrix[1,3],  cor_matrix[1,2]-cor_matrix[1,3])\n\n#&gt; [1] \"The plots show that the effect of the instrument on the treatment and on the outcome goes in the same direction (prerequisite 5 fullfilled). There is a correlation between the instrument 'rand_enc' and the treatment 'used_ftr', so the 4th prerequisite is fullfilled, altough the correlation is rather low (about 0.20). There is also a small correlation between the instrument 'rand_enc' and the outcome 'time_spent' of about 0.13. The correlation between the instrument and the treatment is only a little higher (0.07) than the correlation between the treatment and the outcome, so the combination of treatment and instrument is not very suiting and the instrumental variable estimation is not a very adequate procedure in the given case.\"\n\n\n\n\n6 Assignement 4\n\niv_estimate&lt;-iv_robust(time_spent~used_ftr|rand_enc, rand_enc_data)\nsummary(iv_estimate)\n\n#&gt; \n#&gt; Call:\n#&gt; iv_robust(formula = time_spent ~ used_ftr | rand_enc, data = rand_enc_data)\n#&gt; \n#&gt; Standard error type:  HC2 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value  Pr(&gt;|t|) CI Lower CI Upper   DF\n#&gt; (Intercept)   19.312     0.2248   85.89 0.000e+00   18.872    19.75 9998\n#&gt; used_ftr       9.738     0.5353   18.19 8.716e-73    8.689    10.79 9998\n#&gt; \n#&gt; Multiple R-squared:  0.4921 ,    Adjusted R-squared:  0.492 \n#&gt; F-statistic:   331 on 1 and 9998 DF,  p-value: &lt; 2.2e-16\n\nsprintf(\"The naive estimate (%.2f) has an upward bias compared to the instrumental variable estimate (%.2f). Though the validity of the instrumental variable estimate can also be questioned (see Assignment 3).\", lm_2[[\"coefficients\"]][[\"used_ftr\"]], iv_estimate[[\"coefficients\"]][[\"used_ftr\"]])\n\n#&gt; [1] \"The naive estimate (10.82) has an upward bias compared to the instrumental variable estimate (9.74). Though the validity of the instrumental variable estimate can also be questioned (see Assignment 3).\""
  },
  {
    "objectID": "content/01_journal/07_matching.html",
    "href": "content/01_journal/07_matching.html",
    "title": "Matching and Subclassification",
    "section": "",
    "text": "library(tidyverse)\n\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.4     ✔ readr     2.1.4\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.1\n#&gt; ✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n#&gt; ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n#&gt; ✔ purrr     1.0.2     \n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(dagitty)\nlibrary(ggdag)\n\n#&gt; \n#&gt; Attache Paket: 'ggdag'\n#&gt; \n#&gt; Das folgende Objekt ist maskiert 'package:stats':\n#&gt; \n#&gt;     filter\n\nlibrary(MatchIt)"
  },
  {
    "objectID": "content/01_journal/05_dag.html",
    "href": "content/01_journal/05_dag.html",
    "title": "Directed Acyclic Graphs",
    "section": "",
    "text": "#library(tidyverse)\n#library(dagitty)\n#library(ggdag)\n\nsetwd(\"D:/CausalDataScience/cdsba-LukasB2324/content/01_journal\")"
  },
  {
    "objectID": "content/01_journal/06_rct.html",
    "href": "content/01_journal/06_rct.html",
    "title": "Randomized Controlled Trials",
    "section": "",
    "text": "library(tidyverse)\n\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.4     ✔ readr     2.1.4\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.1\n#&gt; ✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n#&gt; ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n#&gt; ✔ purrr     1.0.2     \n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(dagitty)\nlibrary(ggdag)\n\n#&gt; \n#&gt; Attache Paket: 'ggdag'\n#&gt; \n#&gt; Das folgende Objekt ist maskiert 'package:stats':\n#&gt; \n#&gt;     filter"
  },
  {
    "objectID": "content/01_journal/08_did.html",
    "href": "content/01_journal/08_did.html",
    "title": "Difference-in-Differences",
    "section": "",
    "text": "1 Load packages\n\nlibrary(tidyverse)\n\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.4     ✔ readr     2.1.4\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.1\n#&gt; ✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n#&gt; ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n#&gt; ✔ purrr     1.0.2     \n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(dagitty)\nlibrary(ggdag)\n\n#&gt; \n#&gt; Attache Paket: 'ggdag'\n#&gt; \n#&gt; Das folgende Objekt ist maskiert 'package:stats':\n#&gt; \n#&gt;     filter\n\nlibrary(MatchIt)\n\n\n\n2 Load data\n\nsetwd(\"D:/CausalDataScience/cdsba-LukasB2324/content/01_journal\")\nhospital_data&lt;-readRDS(\"Data/hospdd.rds\")\n\n\n\n3 Assignment 1\n\nhospital_data_zoom_in  &lt;- hospital_data %&gt;% filter(month %in% 3:4)\n\nbefore_control &lt;- hospital_data_zoom_in %&gt;%\n  filter(hospital %in% 19:46, month == 3) %&gt;% \n  pull(satis)\nbefore_treatment &lt;- hospital_data_zoom_in %&gt;%\n  filter(hospital %in% 1:18, month == 3) %&gt;% \n  pull(satis)\nmean_before_control &lt;- mean(before_control)\nmean_before_treatment &lt;- mean(before_treatment)\ndiff_before &lt;- mean_before_treatment - mean_before_control\n\nafter_control &lt;- hospital_data_zoom_in %&gt;%\n  filter(hospital %in% 19:46, month == 4) %&gt;% \n  pull(satis)\nafter_treatment &lt;- hospital_data_zoom_in %&gt;%\n  filter(hospital %in% 1:18, month == 4) %&gt;% \n  pull(satis)\nmean_after_control &lt;- mean(after_control)\nmean_after_treatment &lt;- mean(after_treatment)\n\ndifffter &lt;- mean_after_treatment - mean_after_control\n\ndiff_diff &lt;- difffter - diff_before\nsprintf(\"Estimate of the mean satisfaction for treated hospitals before the treatment: %.2f; Estimate of the mean satisfaction for control hospitals before the treatment: %.2f; Estimate of the mean satisfaction for treated hospitals after the treatment: %.2f; Estimate of the mean satisfaction for control hospitals after the treatment: %.2f; Estimate of the difference-in-differences: %.2f\", mean_before_treatment, mean_before_control, mean_after_treatment, mean_after_control, diff_diff)\n\n#&gt; [1] \"Estimate of the mean satisfaction for treated hospitals before the treatment: 3.53; Estimate of the mean satisfaction for control hospitals before the treatment: 3.42; Estimate of the mean satisfaction for treated hospitals after the treatment: 4.34; Estimate of the mean satisfaction for control hospitals after the treatment: 3.40; Estimate of the difference-in-differences: 0.82\"\n\n\n\n\n4 Assignment 2\n\nlm_hospitals&lt;-lm(satis ~ as.factor(hospital)+frequency+as.factor(month)+procedure, data = hospital_data)\nsummary(lm_hospitals)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = satis ~ as.factor(hospital) + frequency + as.factor(month) + \n#&gt;     procedure, data = hospital_data)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -3.2699 -0.4604  0.0047  0.4574  4.2569 \n#&gt; \n#&gt; Coefficients:\n#&gt;                        Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)            3.054807   0.058337  52.365  &lt; 2e-16 ***\n#&gt; as.factor(hospital)2   0.369283   0.077169   4.785 1.74e-06 ***\n#&gt; as.factor(hospital)3   0.531657   0.079065   6.724 1.90e-11 ***\n#&gt; as.factor(hospital)4   0.239008   0.073704   3.243  0.00119 ** \n#&gt; as.factor(hospital)5  -0.187606   0.073920  -2.538  0.01117 *  \n#&gt; as.factor(hospital)6   0.422811   0.073769   5.732 1.03e-08 ***\n#&gt; as.factor(hospital)7   1.395230   0.071221  19.590  &lt; 2e-16 ***\n#&gt; as.factor(hospital)8   0.073894   0.076056   0.972  0.33130    \n#&gt; as.factor(hospital)9  -1.541417   0.078040 -19.752  &lt; 2e-16 ***\n#&gt; as.factor(hospital)10  1.666597   0.077009  21.642  &lt; 2e-16 ***\n#&gt; as.factor(hospital)11  0.205881   0.076085   2.706  0.00683 ** \n#&gt; as.factor(hospital)12 -0.088643   0.077981  -1.137  0.25569    \n#&gt; as.factor(hospital)13  0.474560   0.075263   6.305 3.04e-10 ***\n#&gt; as.factor(hospital)14  0.216930   0.079097   2.743  0.00611 ** \n#&gt; as.factor(hospital)15 -0.180409   0.079223  -2.277  0.02280 *  \n#&gt; as.factor(hospital)16  1.413378   0.076976  18.361  &lt; 2e-16 ***\n#&gt; as.factor(hospital)17  0.394071   0.080363   4.904 9.61e-07 ***\n#&gt; as.factor(hospital)18  0.152851   0.093493   1.635  0.10211    \n#&gt; as.factor(hospital)19 -0.747270   0.080883  -9.239  &lt; 2e-16 ***\n#&gt; as.factor(hospital)20  0.051616   0.078844   0.655  0.51270    \n#&gt; as.factor(hospital)21  1.184714   0.083346  14.214  &lt; 2e-16 ***\n#&gt; as.factor(hospital)22  0.751926   0.082314   9.135  &lt; 2e-16 ***\n#&gt; as.factor(hospital)23  0.671462   0.080992   8.290  &lt; 2e-16 ***\n#&gt; as.factor(hospital)24 -0.341779   0.086468  -3.953 7.80e-05 ***\n#&gt; as.factor(hospital)25  0.606550   0.092573   6.552 6.06e-11 ***\n#&gt; as.factor(hospital)26  0.192880   0.078897   2.445  0.01452 *  \n#&gt; as.factor(hospital)27 -0.407223   0.076356  -5.333 9.94e-08 ***\n#&gt; as.factor(hospital)28  0.673916   0.083503   8.071 8.12e-16 ***\n#&gt; as.factor(hospital)29  0.193398   0.080185   2.412  0.01589 *  \n#&gt; as.factor(hospital)30 -0.173233   0.095038  -1.823  0.06838 .  \n#&gt; as.factor(hospital)31  0.488159   0.078912   6.186 6.50e-10 ***\n#&gt; as.factor(hospital)32 -0.343561   0.079867  -4.302 1.72e-05 ***\n#&gt; as.factor(hospital)33 -0.480461   0.078927  -6.087 1.21e-09 ***\n#&gt; as.factor(hospital)34  0.004954   0.074352   0.067  0.94688    \n#&gt; as.factor(hospital)35  0.354500   0.076347   4.643 3.49e-06 ***\n#&gt; as.factor(hospital)36  2.124121   0.077139  27.536  &lt; 2e-16 ***\n#&gt; as.factor(hospital)37  0.122876   0.092438   1.329  0.18380    \n#&gt; as.factor(hospital)38 -0.077458   0.077954  -0.994  0.32043    \n#&gt; as.factor(hospital)39 -0.041024   0.082086  -0.500  0.61725    \n#&gt; as.factor(hospital)40  1.106449   0.077972  14.190  &lt; 2e-16 ***\n#&gt; as.factor(hospital)41 -0.171741   0.076408  -2.248  0.02463 *  \n#&gt; as.factor(hospital)42  0.856891   0.084825  10.102  &lt; 2e-16 ***\n#&gt; as.factor(hospital)43 -0.782887   0.080896  -9.678  &lt; 2e-16 ***\n#&gt; as.factor(hospital)44 -0.014125   0.090375  -0.156  0.87580    \n#&gt; as.factor(hospital)45 -0.217839   0.076349  -2.853  0.00434 ** \n#&gt; as.factor(hospital)46  0.066936   0.082066   0.816  0.41473    \n#&gt; frequency              0.053751   0.007477   7.189 7.19e-13 ***\n#&gt; as.factor(month)2     -0.009608   0.029111  -0.330  0.74138    \n#&gt; as.factor(month)3      0.021969   0.029111   0.755  0.45049    \n#&gt; as.factor(month)4     -0.003284   0.032382  -0.101  0.91923    \n#&gt; as.factor(month)5     -0.009403   0.032382  -0.290  0.77154    \n#&gt; as.factor(month)6     -0.003838   0.032382  -0.119  0.90567    \n#&gt; as.factor(month)7     -0.011194   0.032382  -0.346  0.72958    \n#&gt; procedure              0.847988   0.034101  24.867  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.7213 on 7314 degrees of freedom\n#&gt; Multiple R-squared:  0.5365, Adjusted R-squared:  0.5332 \n#&gt; F-statistic: 159.8 on 53 and 7314 DF,  p-value: &lt; 2.2e-16\n\nsprintf(\"The estaimate for the average treatment effect is %.2f. It is demanded to include a regressor for each hospital and a regressor for each month. This can be done by 'as.factor(hospital)' and 'as.factor(month)'. Without the command 'as.factor' there would be a regressor 'hospital' and a regressor 'month', but there would not be a regressor for each month and each hospital.\", lm_hospitals[[\"coefficients\"]][[\"procedure\"]])\n\n#&gt; [1] \"The estaimate for the average treatment effect is 0.85. It is demanded to include a regressor for each hospital and a regressor for each month. This can be done by 'as.factor(hospital)' and 'as.factor(month)'. Without the command 'as.factor' there would be a regressor 'hospital' and a regressor 'month', but there would not be a regressor for each month and each hospital.\""
  },
  {
    "objectID": "content/01_journal/01_probability.html",
    "href": "content/01_journal/01_probability.html",
    "title": "Probability Theory",
    "section": "",
    "text": "P_S&lt;-0.3\nP_notS&lt;-0.7\n\nP_T_after_S&lt;-0.2\nP_notT_after_S&lt;-0.8\nP_T_after_notS&lt;-0.6\nP_notT_after_notS&lt;-0.4\n\nP_T_and_S&lt;-P_T_after_S*P_S\nP_notT_and_S&lt;-P_notT_after_S*P_S\nP_T_and_notS&lt;-P_T_after_notS*P_notS\nP_notT_and_notS&lt;-P_notT_after_notS*P_notS\n\nsprintf(\"P(T and S) = %.3f; P(T and notS) = %.3f; P(notT and S) = %.3f; P(notT and notS) = %.3f; Sum = %.3f\", P_T_and_S, P_T_and_notS, P_notT_and_S, P_notT_and_notS, P_T_and_S+P_T_and_notS+P_notT_and_S+P_notT_and_notS)\n\n#&gt; [1] \"P(T and S) = 0.060; P(T and notS) = 0.420; P(notT and S) = 0.240; P(notT and notS) = 0.280; Sum = 1.000\""
  },
  {
    "objectID": "content/01_journal/01_probability.html#header-2",
    "href": "content/01_journal/01_probability.html#header-2",
    "title": "Probability Theory",
    "section": "2.1 Header 2",
    "text": "2.1 Header 2\n\nHeader 3\n\nHeader 4\n\nHeader 5\n\nHeader 6"
  },
  {
    "objectID": "content/01_journal/03_regression.html",
    "href": "content/01_journal/03_regression.html",
    "title": "Regression and Statistical Inference",
    "section": "",
    "text": "library(tidyverse)\nsetwd(\"D:/CausalDataScience/cdsba-LukasB2324/content/01_journal\")\ncar_prices&lt;-readRDS(\"Data/car_prices.rds\")"
  },
  {
    "objectID": "content/01_journal/10_rdd.html",
    "href": "content/01_journal/10_rdd.html",
    "title": "Regression Discontinuity",
    "section": "",
    "text": "1 Load packages\n\nlibrary(tidyverse)\n\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.4     ✔ readr     2.1.4\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.1\n#&gt; ✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n#&gt; ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n#&gt; ✔ purrr     1.0.2     \n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(dagitty)\nlibrary(ggdag)\n\n#&gt; \n#&gt; Attache Paket: 'ggdag'\n#&gt; \n#&gt; Das folgende Objekt ist maskiert 'package:stats':\n#&gt; \n#&gt;     filter\n\nlibrary(MatchIt)\nlibrary(estimatr)\nlibrary(rddensity)\n\n\n\n2 Load data\n\nsetwd(\"D:/CausalDataScience/cdsba-LukasB2324/content/01_journal\")\ndf&lt;-readRDS(\"Data/coupon.rds\")\n\n\n\n3 Assignment 1\n\nc0 &lt;- 60\nbw &lt;- c0 + c(-5/2, 5/2) # half the bandwidth\n\ndf_bw_below &lt;- df %&gt;% filter(days_since_last &gt;= bw[1] & days_since_last &lt; c0)\ndf_bw_above &lt;- df %&gt;% filter(days_since_last &gt;= c0 & days_since_last &lt;= bw[2])\n\ndf_bw &lt;- bind_rows(df_bw_above, df_bw_below)\ndim(df_bw)\n\n#&gt; [1] 181   4\n\nmodel_bw_below &lt;- lm(purchase_after ~ days_since_last, df_bw_below)\nmodel_bw_above &lt;- lm(purchase_after ~ days_since_last, df_bw_above)\n\ny0 &lt;- predict(model_bw_below, tibble(days_since_last = c0))\ny1 &lt;- predict(model_bw_above, tibble(days_since_last = c0))\n\nlate &lt;- y1 - y0\nsprintf(\"LATE with half the bandwidth: %.2f\", late)\n\n#&gt; [1] \"LATE with half the bandwidth: 7.36\"\n\n\n\n\n4 Assignment 2\n\nc0 &lt;- 60\nbw &lt;- c0 + c(-5*2, 5*2) # double the bandwidth\n\ndf_bw_below &lt;- df %&gt;% filter(days_since_last &gt;= bw[1] & days_since_last &lt; c0)\ndf_bw_above &lt;- df %&gt;% filter(days_since_last &gt;= c0 & days_since_last &lt;= bw[2])\n\ndf_bw &lt;- bind_rows(df_bw_above, df_bw_below)\ndim(df_bw)\n\n#&gt; [1] 629   4\n\nmodel_bw_below &lt;- lm(purchase_after ~ days_since_last, df_bw_below)\nmodel_bw_above &lt;- lm(purchase_after ~ days_since_last, df_bw_above)\n\ny0 &lt;- predict(model_bw_below, tibble(days_since_last = c0))\ny1 &lt;- predict(model_bw_above, tibble(days_since_last = c0))\n\nlate &lt;- y1 - y0\nsprintf(\"LATE with double the bandwidth: %.2f\", late)\n\n#&gt; [1] \"LATE with double the bandwidth: 9.51\"\n\nsprintf(\"Changing the bandwidth has a noticable influence on the LATE. Especially doubling the bandwidth increases the LATE a lot.\")\n\n#&gt; [1] \"Changing the bandwidth has a noticable influence on the LATE. Especially doubling the bandwidth increases the LATE a lot.\"\n\n\n\n\n5 Assignment 3\n\nshipping_data&lt;-readRDS(\"Data/shipping.rds\")\nc0=30\nrddd &lt;- rddensity(shipping_data$purchase_amount, c = c0)\nsummary(rddd)\n\n#&gt; \n#&gt; Manipulation testing using local polynomial density estimation.\n#&gt; \n#&gt; Number of obs =       6666\n#&gt; Model =               unrestricted\n#&gt; Kernel =              triangular\n#&gt; BW method =           estimated\n#&gt; VCE method =          jackknife\n#&gt; \n#&gt; c = 30                Left of c           Right of c          \n#&gt; Number of obs         3088                3578                \n#&gt; Eff. Number of obs    2221                1955                \n#&gt; Order est. (p)        2                   2                   \n#&gt; Order bias (q)        3                   3                   \n#&gt; BW est. (h)           22.909              20.394              \n#&gt; \n#&gt; Method                T                   P &gt; |T|             \n#&gt; Robust                5.9855              0\n\n\n#&gt; Warning in summary.CJMrddensity(rddd): There are repeated observations. Point\n#&gt; estimates and standard errors have been adjusted. Use option massPoints=FALSE\n#&gt; to suppress this feature.\n\n\n#&gt; \n#&gt; P-values of binomial tests (H0: p=0.5).\n#&gt; \n#&gt; Window Length / 2          &lt;c     &gt;=c    P&gt;|T|\n#&gt; 0.261                      20      26    0.4614\n#&gt; 0.522                      41      65    0.0250\n#&gt; 0.783                      62     107    0.0007\n#&gt; 1.043                      81     136    0.0002\n#&gt; 1.304                     100     169    0.0000\n#&gt; 1.565                     114     196    0.0000\n#&gt; 1.826                     132     227    0.0000\n#&gt; 2.087                     156     263    0.0000\n#&gt; 2.348                     173     298    0.0000\n#&gt; 2.609                     191     331    0.0000\n\nrdd_plot &lt;- rdplotdensity(rddd, shipping_data$purchase_amount, plotN = 1000, xlabel=\"purchase_amount\", ylabel=\"density\")\n\n\n\n\n\n\n\n\nNo, the data of ‘purchase_amount’ is not suited as a running variable with a cut-off at 30€, because the plot shows a sudden large jump at 30€. As can be seen in the plot, the confidence intervals do not overlap."
  },
  {
    "objectID": "content/01_journal/01_probability - Kopie.html",
    "href": "content/01_journal/01_probability - Kopie.html",
    "title": "Probability Theory",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh.\nThis is a .qmd file. It is plain text with special features. Any time you write just like this, it will be compiled to normal text in the website. If you put a # in front of your text, it will create a top level-header.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "content/01_journal/01_probability - Kopie.html#header-2",
    "href": "content/01_journal/01_probability - Kopie.html#header-2",
    "title": "Probability Theory",
    "section": "2.1 Header 2",
    "text": "2.1 Header 2\n\nHeader 3\n\nHeader 4\n\nHeader 5\n\nHeader 6"
  },
  {
    "objectID": "content/01_journal/01_probability.html#percentage-of-customers-using-all-three-devices",
    "href": "content/01_journal/01_probability.html#percentage-of-customers-using-all-three-devices",
    "title": "Probability Theory",
    "section": "2.1 Percentage of customers using ALL three devices",
    "text": "2.1 Percentage of customers using ALL three devices\n\nP_allDevices&lt;-P_SandTandC\nsprintf(\"Percentage of customers using all three devices: %.3f\",P_allDevices)\n\n#&gt; [1] \"Percentage of customers using all three devices: 0.005\""
  },
  {
    "objectID": "content/01_journal/01_probability.html#percentage-of-customers-using-at-least-two-devices",
    "href": "content/01_journal/01_probability.html#percentage-of-customers-using-at-least-two-devices",
    "title": "Probability Theory",
    "section": "2.2 Percentage of customers using AT LEAST two devices",
    "text": "2.2 Percentage of customers using AT LEAST two devices\n\nP_atLeastTwoDevices&lt;-P_SandT_notSandTandC+P_TandC_notSandTandC+P_SandC_notSandTandC+P_SandTandC\nsprintf(\"Percentage of customers using at least two devices: %.3f\", P_atLeastTwoDevices)\n\n#&gt; [1] \"Percentage of customers using at least two devices: 0.199\""
  },
  {
    "objectID": "content/01_journal/01_probability.html#percentage-of-customers-using-only-one-device",
    "href": "content/01_journal/01_probability.html#percentage-of-customers-using-only-one-device",
    "title": "Probability Theory",
    "section": "2.3 Percentage of customers using ONLY one device",
    "text": "2.3 Percentage of customers using ONLY one device\n\nP_onlyOneDevice&lt;-P_S_notT_notC+P_T_notS_notC+P_C_notT_notS\nsprintf(\"Percentage of customers using only one device: %.3f\", P_onlyOneDevice)\n\n#&gt; [1] \"Percentage of customers using only one device: 0.801\""
  },
  {
    "objectID": "content/01_journal/01_probability.html#check-total-probability-has-to-be-1",
    "href": "content/01_journal/01_probability.html#check-total-probability-has-to-be-1",
    "title": "Probability Theory",
    "section": "2.4 Check total probability (has to be 1)",
    "text": "2.4 Check total probability (has to be 1)\n\nP_total&lt;-P_atLeastTwoDevices+P_onlyOneDevice\nsprintf(\"Total probability: %.3f\", P_total)\n\n#&gt; [1] \"Total probability: 1.000\""
  },
  {
    "objectID": "content/01_journal/06_rct.html#include-interaction-for-subgroup-mobile-users",
    "href": "content/01_journal/06_rct.html#include-interaction-for-subgroup-mobile-users",
    "title": "Randomized Controlled Trials",
    "section": "5.1 Include interaction for subgroup mobile users",
    "text": "5.1 Include interaction for subgroup mobile users\n\nlm_3 &lt;- lm(purchase_amount ~ chatbot * mobile_device, abtest_data_mod)\nsummary(lm_3)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = purchase_amount ~ chatbot * mobile_device, data = abtest_data_mod)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt; -16.98 -14.54  -9.95  14.13  65.24 \n#&gt; \n#&gt; Coefficients:\n#&gt;                       Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)            16.9797     1.0152  16.725   &lt;2e-16 ***\n#&gt; chatbot                -7.0301     1.4284  -4.922    1e-06 ***\n#&gt; mobile_device          -0.8727     1.7987  -0.485    0.628    \n#&gt; chatbot:mobile_device  -0.1526     2.5369  -0.060    0.952    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 18.66 on 996 degrees of freedom\n#&gt; Multiple R-squared:  0.03534,    Adjusted R-squared:  0.03244 \n#&gt; F-statistic: 12.16 on 3 and 996 DF,  p-value: 8.034e-08\n\n\nThe calculated CATE for the subgroup mobile_device is -0.1526, but it is statistically not significant."
  },
  {
    "objectID": "content/01_journal/05_dag.html#confounder",
    "href": "content/01_journal/05_dag.html#confounder",
    "title": "Directed Acyclic Graphs",
    "section": "2.1 Confounder",
    "text": "2.1 Confounder\n\nconfounding &lt;- dagify(\n  X ~ Z,\n  Y ~ Z,\n  Y ~ X,\n  coords = list(x = c(Y = 3, Z = 2, X = 1),\n                y = c(Y = 0, Z = 1, X = 0)),\n  labels = list(X = \"parking spots\",\n                Y = \"sales\",\n                Z = \"location\")\n)"
  },
  {
    "objectID": "content/01_journal/05_dag.html#plot-dag",
    "href": "content/01_journal/05_dag.html#plot-dag",
    "title": "Directed Acyclic Graphs",
    "section": "2.2 Plot DAG",
    "text": "2.2 Plot DAG\n\nggdag(confounding) +\n  geom_dag_point() +\n  geom_dag_text() +\n  geom_dag_edges() +\n  geom_dag_label_repel(aes(label = label)) +\n  theme_dag_blank()"
  },
  {
    "objectID": "content/01_journal/05_dag.html#not-conditioning-on-subscription-1",
    "href": "content/01_journal/05_dag.html#not-conditioning-on-subscription-1",
    "title": "Directed Acyclic Graphs",
    "section": "5.1 NOT conditioning on subscription",
    "text": "5.1 NOT conditioning on subscription\n\nsimps_not_cond &lt;- ggplot(customer_sat[,1:2], aes(x = follow_ups, y = satisfaction)) +\n  geom_point(alpha = .8) +\n  stat_smooth(method = \"lm\", se = F)\nsimps_not_cond\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "content/01_journal/05_dag.html#conditioning-on-subscription-1",
    "href": "content/01_journal/05_dag.html#conditioning-on-subscription-1",
    "title": "Directed Acyclic Graphs",
    "section": "5.2 Conditioning on subscription",
    "text": "5.2 Conditioning on subscription\n\nsimps_cond &lt;- ggplot(customer_sat, aes(x = follow_ups, y = satisfaction, color = subscription)) +\n  geom_point(alpha = .8) +\n  stat_smooth(method = \"lm\", se = F) +\n  theme(legend.position = \"right\")\nsimps_cond\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "content/01_journal/07_matching.html#plotting-data",
    "href": "content/01_journal/07_matching.html#plotting-data",
    "title": "Matching and Subclassification",
    "section": "3.1 Plotting data",
    "text": "3.1 Plotting data\n\nplot_age &lt;- ggplot(Membership_data[,c(1,5)], aes(x = age, y = avg_purch)) +\n  geom_point(alpha = .8) +\n  stat_smooth(method = \"lm\", se = F)\n\nplot_sex &lt;- ggplot(Membership_data[,c(2,5)], aes(x = sex, y = avg_purch)) +\n  geom_point(alpha = .8) +\n  stat_smooth(method = \"lm\", se = F)\n\nplot_pre_avg_purch &lt;- ggplot(Membership_data[,c(3,5)], aes(x = pre_avg_purch, y = avg_purch)) +\n  geom_point(alpha = .8) +\n  stat_smooth(method = \"lm\", se = F)\n\nplot_card &lt;- ggplot(Membership_data[,c(4,5)], aes(x = card, y = avg_purch)) +\n  geom_point(alpha = .8) +\n  stat_smooth(method = \"lm\", se = F)\n\nplot_age\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nplot_sex\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nplot_pre_avg_purch\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nplot_card\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nplot_age_pre_avg_purch&lt;- ggplot(Membership_data[,c(1,3)], aes(x = age, y = pre_avg_purch)) +\n  geom_point(alpha = .8) +\n  stat_smooth(method = \"lm\", se = F)\n\nplot_age_card&lt;- ggplot(Membership_data[,c(1,4)], aes(x = age, y = card)) +\n  geom_point(alpha = .8) +\n  stat_smooth(method = \"lm\", se = F)\n\nplot_pre_avg_purch_card&lt;- ggplot(Membership_data[,c(3,4)], aes(x = pre_avg_purch, y = card)) +\n  geom_point(alpha = .8) +\n  stat_smooth(method = \"lm\", se = F)\n\nplot_age_pre_avg_purch\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nplot_age_card\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nplot_pre_avg_purch_card\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "content/01_journal/07_matching.html#dag",
    "href": "content/01_journal/07_matching.html#dag",
    "title": "Matching and Subclassification",
    "section": "3.2 DAG",
    "text": "3.2 DAG\n\ndag_model &lt;- 'dag {\nbb=\"0,0,1,1\"\nage [exposure,pos=\"0.075,0.4\"]\navg_purch [outcome,pos=\"0.4,0.4\"]\ncard [pos=\"0.2,0.2\"]\npre_avg_purch [pos=\"0.2,0.6\"]\nage -&gt; avg_purch\nage -&gt; pre_avg_purch\npre_avg_purch -&gt; card\nage -&gt; card\ncard -&gt; avg_purch\npre_avg_purch -&gt; avg_purch\n}\n'\n\nggdag(dag_model) +\n  geom_dag_point() +\n  geom_dag_text() +\n  geom_dag_edges() +\n  #geom_dag_label_repel(aes(label = label)) +\n  theme_dag_blank() +\n  geom_dag_text(colour = \"red\")"
  },
  {
    "objectID": "content/01_journal/03_regression.html#fit-model-and-print-summary",
    "href": "content/01_journal/03_regression.html#fit-model-and-print-summary",
    "title": "Regression and Statistical Inference",
    "section": "5.1 Fit model and print summary",
    "text": "5.1 Fit model and print summary\n\nlm_mod &lt;- lm(price~., car_prices)\nsummary(lm_mod)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = price ~ ., data = car_prices)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt;  -5662  -1120      0    798   9040 \n#&gt; \n#&gt; Coefficients:\n#&gt;                        Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)          -36269.965  15460.866  -2.346 0.020354 *  \n#&gt; aspirationturbo        1846.206   1041.391   1.773 0.078386 .  \n#&gt; doornumbertwo           242.523    571.929   0.424 0.672172    \n#&gt; carbodyhardtop        -3691.743   1424.825  -2.591 0.010561 *  \n#&gt; carbodyhatchback      -3344.335   1238.359  -2.701 0.007757 ** \n#&gt; carbodysedan          -2292.820   1356.014  -1.691 0.093043 .  \n#&gt; carbodywagon          -3427.921   1490.285  -2.300 0.022885 *  \n#&gt; drivewheelfwd          -504.564   1076.623  -0.469 0.640030    \n#&gt; drivewheelrwd           -15.446   1268.070  -0.012 0.990299    \n#&gt; enginelocationrear     6643.492   2572.275   2.583 0.010806 *  \n#&gt; wheelbase               -30.197     92.776  -0.325 0.745294    \n#&gt; carlength               -29.740     51.672  -0.576 0.565824    \n#&gt; carwidth                731.819    244.533   2.993 0.003258 ** \n#&gt; carheight               123.195    134.607   0.915 0.361617    \n#&gt; curbweight                2.612      1.781   1.467 0.144706    \n#&gt; enginetypedohcv       -8541.957   4749.685  -1.798 0.074219 .  \n#&gt; enginetypel             978.748   1786.384   0.548 0.584619    \n#&gt; enginetypeohc          3345.252    933.001   3.585 0.000461 ***\n#&gt; enginetypeohcf          972.919   1625.631   0.598 0.550462    \n#&gt; enginetypeohcv        -6222.322   1236.415  -5.033 1.43e-06 ***\n#&gt; cylindernumberfive   -11724.540   3019.192  -3.883 0.000157 ***\n#&gt; cylindernumberfour   -11549.326   3177.177  -3.635 0.000387 ***\n#&gt; cylindernumbersix     -7151.398   2247.230  -3.182 0.001793 ** \n#&gt; cylindernumberthree   -4318.929   4688.833  -0.921 0.358545    \n#&gt; cylindernumbertwelve -11122.209   4196.494  -2.650 0.008946 ** \n#&gt; enginesize              125.934     26.541   4.745 5.00e-06 ***\n#&gt; fuelsystem2bbl          177.136    883.615   0.200 0.841400    \n#&gt; fuelsystemmfi         -3041.018   2576.996  -1.180 0.239934    \n#&gt; fuelsystemmpfi          359.278   1001.529   0.359 0.720326    \n#&gt; fuelsystemspdi        -2543.890   1363.546  -1.866 0.064140 .  \n#&gt; fuelsystemspfi          514.766   2499.229   0.206 0.837107    \n#&gt; boreratio             -1306.740   1642.221  -0.796 0.427516    \n#&gt; stroke                -4527.137    922.732  -4.906 2.49e-06 ***\n#&gt; compressionratio       -737.901    555.960  -1.327 0.186539    \n#&gt; horsepower               10.293     22.709   0.453 0.651035    \n#&gt; peakrpm                   2.526      0.634   3.983 0.000108 ***\n#&gt; citympg                 -90.352    166.647  -0.542 0.588538    \n#&gt; highwaympg              154.858    167.148   0.926 0.355761    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 2189 on 143 degrees of freedom\n#&gt; Multiple R-squared:  0.9415, Adjusted R-squared:  0.9264 \n#&gt; F-statistic: 62.21 on 37 and 143 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "content/01_journal/03_regression.html#test-if-seat_heating-having-the-same-value-in-every-row-causes-the-coefficients-of-the-regression-to-be-na",
    "href": "content/01_journal/03_regression.html#test-if-seat_heating-having-the-same-value-in-every-row-causes-the-coefficients-of-the-regression-to-be-na",
    "title": "Regression and Statistical Inference",
    "section": "7.1 Test, if seat_heating having the same value in every row causes the coefficients of the regression to be ‘NA’",
    "text": "7.1 Test, if seat_heating having the same value in every row causes the coefficients of the regression to be ‘NA’\n\ncar_prices_expanded[2,23]&lt;-FALSE\nlm_mod_3&lt;-lm(price~., car_prices_expanded)\nsummary(lm_mod_3)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = price ~ ., data = car_prices_expanded)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -5574.7 -1147.8     0.0   875.5  8903.9 \n#&gt; \n#&gt; Coefficients:\n#&gt;                        Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)          -3.613e+04  1.539e+04  -2.348 0.020277 *  \n#&gt; aspirationturbo       1.816e+03  1.037e+03   1.751 0.082035 .  \n#&gt; doornumbertwo         2.831e+02  5.699e+02   0.497 0.620162    \n#&gt; carbodyhardtop       -3.240e+03  1.449e+03  -2.236 0.026935 *  \n#&gt; carbodyhatchback     -2.829e+03  1.278e+03  -2.213 0.028510 *  \n#&gt; carbodysedan         -1.824e+03  1.385e+03  -1.318 0.189754    \n#&gt; carbodywagon         -3.036e+03  1.506e+03  -2.016 0.045663 *  \n#&gt; drivewheelfwd        -4.543e+02  1.072e+03  -0.424 0.672394    \n#&gt; drivewheelrwd         1.508e+01  1.262e+03   0.012 0.990487    \n#&gt; enginelocationrear    6.552e+03  2.561e+03   2.558 0.011569 *  \n#&gt; wheelbase            -2.014e+01  9.259e+01  -0.218 0.828111    \n#&gt; carlength            -3.260e+01  5.147e+01  -0.633 0.527538    \n#&gt; carwidth              7.223e+02  2.435e+02   2.966 0.003535 ** \n#&gt; carheight             1.449e+02  1.347e+02   1.075 0.284209    \n#&gt; curbweight            2.939e+00  1.786e+00   1.646 0.102035    \n#&gt; enginetypedohcv      -9.067e+03  4.741e+03  -1.913 0.057821 .  \n#&gt; enginetypel           1.347e+03  1.795e+03   0.751 0.454171    \n#&gt; enginetypeohc         3.713e+03  9.598e+02   3.869 0.000166 ***\n#&gt; enginetypeohcf        1.642e+03  1.677e+03   0.979 0.329203    \n#&gt; enginetypeohcv       -5.996e+03  1.240e+03  -4.837 3.39e-06 ***\n#&gt; cylindernumberfive   -1.250e+04  3.048e+03  -4.100 6.92e-05 ***\n#&gt; cylindernumberfour   -1.231e+04  3.202e+03  -3.845 0.000181 ***\n#&gt; cylindernumbersix    -7.640e+03  2.260e+03  -3.381 0.000934 ***\n#&gt; cylindernumberthree  -5.257e+03  4.708e+03  -1.117 0.266018    \n#&gt; cylindernumbertwelve -1.101e+04  4.178e+03  -2.635 0.009352 ** \n#&gt; enginesize            1.201e+02  2.670e+01   4.498 1.41e-05 ***\n#&gt; fuelsystem2bbl        3.526e+02  8.871e+02   0.398 0.691593    \n#&gt; fuelsystemmfi        -2.873e+03  2.568e+03  -1.119 0.265056    \n#&gt; fuelsystemmpfi        5.010e+02  1.001e+03   0.500 0.617591    \n#&gt; fuelsystemspdi       -2.385e+03  1.361e+03  -1.752 0.081949 .  \n#&gt; fuelsystemspfi        6.495e+02  2.489e+03   0.261 0.794539    \n#&gt; boreratio            -1.308e+03  1.635e+03  -0.800 0.424833    \n#&gt; stroke               -4.190e+03  9.448e+02  -4.435 1.83e-05 ***\n#&gt; compressionratio     -6.931e+02  5.542e+02  -1.251 0.213163    \n#&gt; horsepower            1.264e+01  2.266e+01   0.558 0.577745    \n#&gt; peakrpm               2.612e+00  6.337e-01   4.121 6.37e-05 ***\n#&gt; citympg              -8.401e+01  1.659e+02  -0.506 0.613436    \n#&gt; highwaympg            1.582e+02  1.664e+02   0.951 0.343345    \n#&gt; seat_heatingTRUE     -4.017e+03  2.641e+03  -1.521 0.130503    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 2179 on 142 degrees of freedom\n#&gt; Multiple R-squared:  0.9424, Adjusted R-squared:  0.927 \n#&gt; F-statistic: 61.19 on 38 and 142 DF,  p-value: &lt; 2.2e-16\n\n\nFor the parameter seat_heating the coefficients of the linear regression are NA. This is caused by seat_heating having the same value in every row. Therefore, it is not possible to determine the influence of the parameter seat_heating on the price. If seat_heating=FALSE is set for one of the rows, the regression renders numerical results for the coefficents instead of NA."
  },
  {
    "objectID": "content/01_journal/04_causality.html#the-original-image",
    "href": "content/01_journal/04_causality.html#the-original-image",
    "title": "Causality",
    "section": "1 The original image",
    "text": "1 The original image\n\n\n\nCaption"
  },
  {
    "objectID": "content/01_journal/05_dag.html#not-conditioning-on-subscription",
    "href": "content/01_journal/05_dag.html#not-conditioning-on-subscription",
    "title": "Directed Acyclic Graphs",
    "section": "3.1 NOT conditioning on subscription",
    "text": "3.1 NOT conditioning on subscription\n\nlm_2_1&lt;-lm(satisfaction~., customer_sat[,1:2])\nsummary(lm_2_1)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = satisfaction ~ ., data = customer_sat[, 1:2])\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -12.412  -5.257   1.733   4.506  12.588 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  78.8860     4.2717  18.467 1.04e-10 ***\n#&gt; follow_ups   -3.3093     0.6618  -5.001 0.000243 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 7.923 on 13 degrees of freedom\n#&gt; Multiple R-squared:  0.658,  Adjusted R-squared:  0.6316 \n#&gt; F-statistic: 25.01 on 1 and 13 DF,  p-value: 0.0002427"
  },
  {
    "objectID": "content/01_journal/05_dag.html#conditioning-on-subscription",
    "href": "content/01_journal/05_dag.html#conditioning-on-subscription",
    "title": "Directed Acyclic Graphs",
    "section": "3.2 Conditioning on subscription",
    "text": "3.2 Conditioning on subscription\n\nlm_2_2&lt;-lm(satisfaction~., customer_sat)\nsummary(lm_2_2)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = satisfaction ~ ., data = customer_sat)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -4.3222 -2.1972  0.3167  2.2667  3.9944 \n#&gt; \n#&gt; Coefficients:\n#&gt;                      Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)           26.7667     6.6804   4.007  0.00206 ** \n#&gt; follow_ups             2.1944     0.7795   2.815  0.01682 *  \n#&gt; subscriptionPremium   44.7222     5.6213   7.956 6.88e-06 ***\n#&gt; subscriptionPremium+  18.0722     2.1659   8.344 4.37e-06 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 2.958 on 11 degrees of freedom\n#&gt; Multiple R-squared:  0.9597, Adjusted R-squared:  0.9487 \n#&gt; F-statistic: 87.21 on 3 and 11 DF,  p-value: 5.956e-08"
  },
  {
    "objectID": "content/01_journal/07_matching.html#plotting-the-data-to-check-the-relationships",
    "href": "content/01_journal/07_matching.html#plotting-the-data-to-check-the-relationships",
    "title": "Matching and Subclassification",
    "section": "3.1 Plotting the data to check the relationships",
    "text": "3.1 Plotting the data to check the relationships\n\nplot_age &lt;- ggplot(Membership_data[,c(1,5)], aes(x = age, y = avg_purch)) +\n  geom_point(alpha = .8) +\n  stat_smooth(method = \"lm\", se = F)\n\nplot_sex &lt;- ggplot(Membership_data[,c(2,5)], aes(x = sex, y = avg_purch)) +\n  geom_point(alpha = .8) +\n  stat_smooth(method = \"lm\", se = F)\n\nplot_pre_avg_purch &lt;- ggplot(Membership_data[,c(3,5)], aes(x = pre_avg_purch, y = avg_purch)) +\n  geom_point(alpha = .8) +\n  stat_smooth(method = \"lm\", se = F)\n\nplot_card &lt;- ggplot(Membership_data[,c(4,5)], aes(x = card, y = avg_purch)) +\n  geom_point(alpha = .8) +\n  stat_smooth(method = \"lm\", se = F)\n\nplot_age\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nplot_sex\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nplot_pre_avg_purch\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nplot_card\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nplot_age_pre_avg_purch&lt;- ggplot(Membership_data[,c(1,3)], aes(x = age, y = pre_avg_purch)) +\n  geom_point(alpha = .8) +\n  stat_smooth(method = \"lm\", se = F)\n\nplot_age_card&lt;- ggplot(Membership_data[,c(1,4)], aes(x = age, y = card)) +\n  geom_point(alpha = .8) +\n  stat_smooth(method = \"lm\", se = F)\n\nplot_pre_avg_purch_card&lt;- ggplot(Membership_data[,c(3,4)], aes(x = pre_avg_purch, y = card)) +\n  geom_point(alpha = .8) +\n  stat_smooth(method = \"lm\", se = F)\n\nplot_age_pre_avg_purch\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nplot_age_card\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nplot_pre_avg_purch_card\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'"
  }
]